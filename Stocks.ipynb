{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO7Sk790+tbFI37e6d9Sobo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sfwtopoulos/stocks/blob/master/Stocks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qemdNp8GaAQL",
        "colab_type": "code",
        "outputId": "5d605e20-887d-4ec5-b9c9-33c67fd83952",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#!git init\n",
        "#!git config --global user.email \"sfwtopoulos@gmail.com\"\n",
        "#!git config --global user.name \"sfwtopoulos\"\n",
        "#!git add -A\n",
        "#!git commit -m \"YO\"\n",
        "#!git remote rm origin\n",
        "#!git remote add origin https://sfwtopoulos:%21%3D%25%28wy%27%22E3%2BE4WJK8%3C%25Sgithub@github.com/sfwtopoulos/stocks.git\n",
        "#!git clone https://github.com/sfwtopoulos/stocks\n",
        "#!git pull\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Initialized empty Git repository in /content/.git/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RiMnCcpheA2-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import math\n",
        "import warnings\n",
        "import numpy as np\n",
        "import time\n",
        "import pandas_datareader as pdr\n",
        "\n",
        "#from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# specify to ignore warning messages\n",
        "#warnings.filterwarnings(\"ignore\") "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rCCmauyULvM6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "fb85df6a-8c4b-435c-f779-577bd8671336"
      },
      "source": [
        "import keras\n",
        "from keras.layers import LSTM\n",
        "from keras.models import Sequential\n",
        "from keras.layers.wrappers import TimeDistributed\n",
        "from keras.layers.core import Dense, Activation, Dropout"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n0IZA2fPUD-_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "#not all needed"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y1GtvT7RSUkN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Data import from git repo\n",
        "url = 'https://raw.githubusercontent.com/sfwtopoulos/stocks/master/stocks_dataset/combined.csv'\n",
        "#df1 = pd.read_csv(url, error_bad_lines=False)\n",
        "dfstocks = pd.read_csv(url, sep=',')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXbxTv7dN3Qy",
        "colab_type": "code",
        "outputId": "f7cacb91-fd44-45fe-f6bc-ec27a75c981a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "for col in dfstocks.columns: \n",
        "    print(col) "
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Date\n",
            " Close/Last\n",
            " Volume\n",
            " Open\n",
            " High\n",
            " Low\n",
            " AAPL\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "brASTrbbCiQ7",
        "colab_type": "code",
        "outputId": "6d30c9b2-3a63-4e64-9e3d-49a0dff52d5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "#fix column names\n",
        "dfstocks=dfstocks.rename({' AAPL':'Company', ' Close/Last':'Close', ' Volume':'Volume', ' Open':'Open', ' High':'High', ' Low':'Low'}, axis=1);\n",
        "for col in dfstocks.columns: \n",
        "    print(col) "
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Date\n",
            "Close\n",
            "Volume\n",
            "Open\n",
            "High\n",
            "Low\n",
            "Company\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a22eQ-a9PxVx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#drop $sign from values\n",
        "dfstocks.Close=dfstocks['Close'].astype(str)\n",
        "dfstocks.Close=dfstocks.Close.apply(lambda x: x.replace('$',''))\n",
        "dfstocks.Open=dfstocks['Open'].astype(str)\n",
        "dfstocks.Open=dfstocks.Open.apply(lambda x: x.replace('$',''))\n",
        "dfstocks.High=dfstocks['High'].astype(str)\n",
        "dfstocks.High=dfstocks.High.apply(lambda x: x.replace('$',''))\n",
        "dfstocks.Low=dfstocks['Low'].astype(str)\n",
        "dfstocks.Low=dfstocks.Low.apply(lambda x: x.replace('$',''))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "afYv0Wbycmb6",
        "colab_type": "code",
        "outputId": "1abc13ce-ba63-41a5-9b65-9cf991570216",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#drop rows containing nan or header from the csv files\n",
        "dfstocks=dfstocks[~dfstocks.Low.str.contains(\"nan\")]\n",
        "dfstocks=dfstocks[~dfstocks.Low.str.contains(\"Low\")]\n",
        "dfstocks.reset_index(drop=True, inplace=True)\n",
        "dfstocks.Date.count()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "229286"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4DG2XfzYa649",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#sort dataframe based on date and Company Name\n",
        "  dfstocks = dfstocks.sort_values(['Date', 'Company'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oCqTF2_mPxpN",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JrRIDlF4HdO2",
        "colab_type": "code",
        "outputId": "88c05574-c94f-4aa2-87e9-373eb26573aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "dfstocks.head(100)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Company</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1761</th>\n",
              "      <td>01/02/2013</td>\n",
              "      <td>78.4328</td>\n",
              "      <td>139906732</td>\n",
              "      <td>79.1171</td>\n",
              "      <td>79.2857</td>\n",
              "      <td>77.3757</td>\n",
              "      <td>AAPL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4248</th>\n",
              "      <td>01/02/2013</td>\n",
              "      <td>35.12</td>\n",
              "      <td>13767660</td>\n",
              "      <td>34.92</td>\n",
              "      <td>35.4</td>\n",
              "      <td>34.1</td>\n",
              "      <td>ABBV</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6025</th>\n",
              "      <td>01/02/2013</td>\n",
              "      <td>32.05</td>\n",
              "      <td>20266410</td>\n",
              "      <td>32.3</td>\n",
              "      <td>32.45</td>\n",
              "      <td>31.64</td>\n",
              "      <td>ABT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8512</th>\n",
              "      <td>01/02/2013</td>\n",
              "      <td>69.06</td>\n",
              "      <td>4039095</td>\n",
              "      <td>67.59</td>\n",
              "      <td>69.06</td>\n",
              "      <td>67.55</td>\n",
              "      <td>ACN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10999</th>\n",
              "      <td>01/02/2013</td>\n",
              "      <td>38.34</td>\n",
              "      <td>6483720</td>\n",
              "      <td>37.92</td>\n",
              "      <td>38.73</td>\n",
              "      <td>37.92</td>\n",
              "      <td>ADBE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10747</th>\n",
              "      <td>01/02/2014</td>\n",
              "      <td>59.29</td>\n",
              "      <td>2745895</td>\n",
              "      <td>59.06</td>\n",
              "      <td>59.53</td>\n",
              "      <td>58.94</td>\n",
              "      <td>ADBE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13234</th>\n",
              "      <td>01/02/2014</td>\n",
              "      <td>168.05</td>\n",
              "      <td>1268722</td>\n",
              "      <td>167.33</td>\n",
              "      <td>170.71</td>\n",
              "      <td>166.5937</td>\n",
              "      <td>AGN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15721</th>\n",
              "      <td>01/02/2014</td>\n",
              "      <td>50.71</td>\n",
              "      <td>9196092</td>\n",
              "      <td>50.81</td>\n",
              "      <td>51.3</td>\n",
              "      <td>50.47</td>\n",
              "      <td>AIG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18208</th>\n",
              "      <td>01/02/2014</td>\n",
              "      <td>53.55</td>\n",
              "      <td>1909106</td>\n",
              "      <td>54.09</td>\n",
              "      <td>54.45</td>\n",
              "      <td>53.5</td>\n",
              "      <td>ALL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20695</th>\n",
              "      <td>01/02/2014</td>\n",
              "      <td>115.795</td>\n",
              "      <td>2528751</td>\n",
              "      <td>114.36</td>\n",
              "      <td>116.19</td>\n",
              "      <td>114.06</td>\n",
              "      <td>AMGN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "             Date     Close      Volume      Open      High        Low Company\n",
              "1761   01/02/2013   78.4328   139906732   79.1171   79.2857    77.3757    AAPL\n",
              "4248   01/02/2013     35.12    13767660     34.92      35.4       34.1    ABBV\n",
              "6025   01/02/2013     32.05    20266410      32.3     32.45      31.64     ABT\n",
              "8512   01/02/2013     69.06     4039095     67.59     69.06      67.55     ACN\n",
              "10999  01/02/2013     38.34     6483720     37.92     38.73      37.92    ADBE\n",
              "...           ...       ...         ...       ...       ...        ...     ...\n",
              "10747  01/02/2014     59.29     2745895     59.06     59.53      58.94    ADBE\n",
              "13234  01/02/2014    168.05     1268722    167.33    170.71   166.5937     AGN\n",
              "15721  01/02/2014     50.71     9196092     50.81      51.3      50.47     AIG\n",
              "18208  01/02/2014     53.55     1909106     54.09     54.45       53.5     ALL\n",
              "20695  01/02/2014   115.795     2528751    114.36    116.19     114.06    AMGN\n",
              "\n",
              "[100 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JcuzyarDrw5l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 762
        },
        "outputId": "e0088230-8b99-474c-b4d6-89e5a3988a4a"
      },
      "source": [
        "dfstocks_split = dfstocks.sample(frac=0.9999,random_state=200)\n",
        "second_split=dfstocks.drop(dfstocks_split.index)\n",
        "second_split"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Company</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>173214</th>\n",
              "      <td>01/05/2011</td>\n",
              "      <td>94.1728</td>\n",
              "      <td>3597597</td>\n",
              "      <td>93.3963</td>\n",
              "      <td>94.7261</td>\n",
              "      <td>92.5616</td>\n",
              "      <td>OXY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95258</th>\n",
              "      <td>01/15/2015</td>\n",
              "      <td>23.5037</td>\n",
              "      <td>31431330</td>\n",
              "      <td>23.7828</td>\n",
              "      <td>23.8925</td>\n",
              "      <td>23.4838</td>\n",
              "      <td>GE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>219831</th>\n",
              "      <td>01/16/2018</td>\n",
              "      <td>133.97</td>\n",
              "      <td>5170230</td>\n",
              "      <td>137.73</td>\n",
              "      <td>137.73</td>\n",
              "      <td>133.87</td>\n",
              "      <td>UTX</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38340</th>\n",
              "      <td>01/25/2013</td>\n",
              "      <td>718.82</td>\n",
              "      <td>1570859</td>\n",
              "      <td>682</td>\n",
              "      <td>719.37</td>\n",
              "      <td>681.05</td>\n",
              "      <td>BKNG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>183867</th>\n",
              "      <td>02/05/2018</td>\n",
              "      <td>74.705</td>\n",
              "      <td>18709640</td>\n",
              "      <td>75.95</td>\n",
              "      <td>78.98</td>\n",
              "      <td>74.68</td>\n",
              "      <td>PYPL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>124920</th>\n",
              "      <td>02/26/2015</td>\n",
              "      <td>42.46</td>\n",
              "      <td>14344290</td>\n",
              "      <td>42.04</td>\n",
              "      <td>42.55</td>\n",
              "      <td>41.97</td>\n",
              "      <td>KO</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16396</th>\n",
              "      <td>04/27/2011</td>\n",
              "      <td>31.7</td>\n",
              "      <td>5420339</td>\n",
              "      <td>32.01</td>\n",
              "      <td>32.01</td>\n",
              "      <td>31.28</td>\n",
              "      <td>AIG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1423</th>\n",
              "      <td>05/07/2014</td>\n",
              "      <td>84.6185</td>\n",
              "      <td>70532231</td>\n",
              "      <td>85.0357</td>\n",
              "      <td>85.3271</td>\n",
              "      <td>83.9614</td>\n",
              "      <td>AAPL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>101334</th>\n",
              "      <td>06/07/2016</td>\n",
              "      <td>731.09</td>\n",
              "      <td>1214733</td>\n",
              "      <td>733.27</td>\n",
              "      <td>736.71</td>\n",
              "      <td>730.8</td>\n",
              "      <td>GOOGL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>175836</th>\n",
              "      <td>06/24/2010</td>\n",
              "      <td>62.4</td>\n",
              "      <td>6184699</td>\n",
              "      <td>62.37</td>\n",
              "      <td>62.99</td>\n",
              "      <td>62.25</td>\n",
              "      <td>PEP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>174572</th>\n",
              "      <td>07/02/2015</td>\n",
              "      <td>94.66</td>\n",
              "      <td>3209616</td>\n",
              "      <td>94.6</td>\n",
              "      <td>94.98</td>\n",
              "      <td>94.21</td>\n",
              "      <td>PEP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6149</th>\n",
              "      <td>07/03/2012</td>\n",
              "      <td>32.415</td>\n",
              "      <td>3199586</td>\n",
              "      <td>32.235</td>\n",
              "      <td>32.5</td>\n",
              "      <td>32.195</td>\n",
              "      <td>ABT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61364</th>\n",
              "      <td>07/08/2010</td>\n",
              "      <td>40.244</td>\n",
              "      <td>8716726</td>\n",
              "      <td>40.7202</td>\n",
              "      <td>40.728</td>\n",
              "      <td>39.7834</td>\n",
              "      <td>COP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>201527</th>\n",
              "      <td>09/16/2011</td>\n",
              "      <td>28.94</td>\n",
              "      <td>34249290</td>\n",
              "      <td>28.82</td>\n",
              "      <td>28.94</td>\n",
              "      <td>28.54</td>\n",
              "      <td>T</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3556</th>\n",
              "      <td>10/01/2015</td>\n",
              "      <td>55.13</td>\n",
              "      <td>9247009</td>\n",
              "      <td>54.68</td>\n",
              "      <td>55.23</td>\n",
              "      <td>53.93</td>\n",
              "      <td>ABBV</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>110942</th>\n",
              "      <td>10/11/2017</td>\n",
              "      <td>147.62</td>\n",
              "      <td>3701258</td>\n",
              "      <td>148.4</td>\n",
              "      <td>148.47</td>\n",
              "      <td>147.28</td>\n",
              "      <td>IBM</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>179223</th>\n",
              "      <td>10/12/2016</td>\n",
              "      <td>88.57</td>\n",
              "      <td>17093450</td>\n",
              "      <td>88.74</td>\n",
              "      <td>89.01</td>\n",
              "      <td>88.33</td>\n",
              "      <td>PG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>222866</th>\n",
              "      <td>11/10/2015</td>\n",
              "      <td>83.53</td>\n",
              "      <td>4302471</td>\n",
              "      <td>83.83</td>\n",
              "      <td>84.79</td>\n",
              "      <td>83.26</td>\n",
              "      <td>WBA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98790</th>\n",
              "      <td>11/18/2010</td>\n",
              "      <td>18.975</td>\n",
              "      <td>15700010</td>\n",
              "      <td>19.01</td>\n",
              "      <td>19.2</td>\n",
              "      <td>18.87</td>\n",
              "      <td>GILD</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1285</th>\n",
              "      <td>11/20/2014</td>\n",
              "      <td>116.31</td>\n",
              "      <td>43148650</td>\n",
              "      <td>114.91</td>\n",
              "      <td>116.86</td>\n",
              "      <td>114.85</td>\n",
              "      <td>AAPL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32900</th>\n",
              "      <td>12/01/2014</td>\n",
              "      <td>288.8073</td>\n",
              "      <td>1146082</td>\n",
              "      <td>286.9253</td>\n",
              "      <td>290.7124</td>\n",
              "      <td>286.6256</td>\n",
              "      <td>BIIB</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>151564</th>\n",
              "      <td>12/22/2017</td>\n",
              "      <td>56.36</td>\n",
              "      <td>11345730</td>\n",
              "      <td>56.6</td>\n",
              "      <td>56.83</td>\n",
              "      <td>56.13</td>\n",
              "      <td>MRK</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43582</th>\n",
              "      <td>12/29/2011</td>\n",
              "      <td>35.27</td>\n",
              "      <td>6422866</td>\n",
              "      <td>35.03</td>\n",
              "      <td>35.3</td>\n",
              "      <td>34.95</td>\n",
              "      <td>BMY</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              Date      Close     Volume  ...       High        Low Company\n",
              "173214  01/05/2011    94.1728    3597597  ...    94.7261    92.5616     OXY\n",
              "95258   01/15/2015    23.5037   31431330  ...    23.8925    23.4838      GE\n",
              "219831  01/16/2018     133.97    5170230  ...     137.73     133.87     UTX\n",
              "38340   01/25/2013     718.82    1570859  ...     719.37     681.05    BKNG\n",
              "183867  02/05/2018     74.705   18709640  ...      78.98      74.68    PYPL\n",
              "124920  02/26/2015      42.46   14344290  ...      42.55      41.97      KO\n",
              "16396   04/27/2011       31.7    5420339  ...      32.01      31.28     AIG\n",
              "1423    05/07/2014    84.6185   70532231  ...    85.3271    83.9614    AAPL\n",
              "101334  06/07/2016     731.09    1214733  ...     736.71      730.8   GOOGL\n",
              "175836  06/24/2010       62.4    6184699  ...      62.99      62.25     PEP\n",
              "174572  07/02/2015      94.66    3209616  ...      94.98      94.21     PEP\n",
              "6149    07/03/2012     32.415    3199586  ...       32.5     32.195     ABT\n",
              "61364   07/08/2010     40.244    8716726  ...     40.728    39.7834     COP\n",
              "201527  09/16/2011      28.94   34249290  ...      28.94      28.54       T\n",
              "3556    10/01/2015      55.13    9247009  ...      55.23      53.93    ABBV\n",
              "110942  10/11/2017     147.62    3701258  ...     148.47     147.28     IBM\n",
              "179223  10/12/2016      88.57   17093450  ...      89.01      88.33      PG\n",
              "222866  11/10/2015      83.53    4302471  ...      84.79      83.26     WBA\n",
              "98790   11/18/2010     18.975   15700010  ...       19.2      18.87    GILD\n",
              "1285    11/20/2014     116.31   43148650  ...     116.86     114.85    AAPL\n",
              "32900   12/01/2014   288.8073    1146082  ...   290.7124   286.6256    BIIB\n",
              "151564  12/22/2017      56.36   11345730  ...      56.83      56.13     MRK\n",
              "43582   12/29/2011      35.27    6422866  ...       35.3      34.95     BMY\n",
              "\n",
              "[23 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "prrbVSjrwiij",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5a8d3e9e-a56e-4724-ab32-59e33c775e9c"
      },
      "source": [
        "second_split.shape[0]"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "23"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eg55-oRdcugD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Prepare Data\n",
        "def get_reg_train_test(timeseries,sequence_length):\n",
        "    # # smoothen out series\n",
        "    # if roll_mean_window:\n",
        "    #     timeseries = timeseries.rolling(roll_mean_window).mean().dropna()\n",
        "\n",
        "    # create windows\n",
        "    result = []\n",
        "    for index in range(len(timeseries) - sequence_length):\n",
        "        result.append(timeseries[index: index + sequence_length])\n",
        "\n",
        "    # normalize data as a variation of 0th index\n",
        "    # if normalize:\n",
        "    #     normalised_data = []\n",
        "    #     for window in result:\n",
        "    #         normalised_window = [((float(p) / float(window[0])) - 1) \\\n",
        "    #                                for p in window]\n",
        "    #         normalised_data.append(normalised_window)\n",
        "    #     result = normalised_data\n",
        "\n",
        "    # identify train-test splits\n",
        "    # convert to arry\n",
        "    result = np.array(result)\n",
        "    #round up 90% of rows\n",
        "    train_size = 0.9\n",
        "    row = round(train_size * result.shape[0])\n",
        "\n",
        "    # split train and test sets 90-10\n",
        "    train = result[:int(row), :]\n",
        "    test = result[int(row):, :]\n",
        "\n",
        "    # scale data in 0-1 range\n",
        "    # scaler = None\n",
        "    # if scale:\n",
        "    #     scaler=MinMaxScaler(feature_range=(0, 1))\n",
        "    #     train = scaler.fit_transform(train)\n",
        "    #     test = scaler.transform(test)\n",
        "\n",
        "    # split independent and dependent variables\n",
        "    x_train = train[:, :-1]\n",
        "    y_train = train[:, -1]\n",
        "\n",
        "\n",
        "    x_test = test[:, :-1]\n",
        "    y_test = test[:, -1]\n",
        "\n",
        "    # Transforms for LSTM input\n",
        "    x_train = np.reshape(x_train, (x_train.shape[0],\n",
        "                                   x_train.shape[1],\n",
        "                                   1))\n",
        "    x_test = np.reshape(x_test, (x_test.shape[0],\n",
        "                                 x_test.shape[1],\n",
        "                                 1))\n",
        "\n",
        "    return x_train,y_train,x_test,y_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RYDjMwcxdk0y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train,y_train,x_test,y_test = get_reg_train_test(second_split.Close, sequence_length=7)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Swk7vPcpU4N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1baf90aa-d82c-457e-de07-a72ff8ef4f84"
      },
      "source": [
        "#print(y_train)\n",
        "print(x_train)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[' 94.1728']\n",
            "  [' 23.5037']\n",
            "  [' 133.97']\n",
            "  [' 718.82']\n",
            "  [' 74.705']\n",
            "  [' 42.46']]\n",
            "\n",
            " [[' 23.5037']\n",
            "  [' 133.97']\n",
            "  [' 718.82']\n",
            "  [' 74.705']\n",
            "  [' 42.46']\n",
            "  [' 31.7']]\n",
            "\n",
            " [[' 133.97']\n",
            "  [' 718.82']\n",
            "  [' 74.705']\n",
            "  [' 42.46']\n",
            "  [' 31.7']\n",
            "  [' 84.6185']]\n",
            "\n",
            " [[' 718.82']\n",
            "  [' 74.705']\n",
            "  [' 42.46']\n",
            "  [' 31.7']\n",
            "  [' 84.6185']\n",
            "  [' 731.09']]\n",
            "\n",
            " [[' 74.705']\n",
            "  [' 42.46']\n",
            "  [' 31.7']\n",
            "  [' 84.6185']\n",
            "  [' 731.09']\n",
            "  [' 62.4']]\n",
            "\n",
            " [[' 42.46']\n",
            "  [' 31.7']\n",
            "  [' 84.6185']\n",
            "  [' 731.09']\n",
            "  [' 62.4']\n",
            "  [' 94.66']]\n",
            "\n",
            " [[' 31.7']\n",
            "  [' 84.6185']\n",
            "  [' 731.09']\n",
            "  [' 62.4']\n",
            "  [' 94.66']\n",
            "  [' 32.415']]\n",
            "\n",
            " [[' 84.6185']\n",
            "  [' 731.09']\n",
            "  [' 62.4']\n",
            "  [' 94.66']\n",
            "  [' 32.415']\n",
            "  [' 40.244']]\n",
            "\n",
            " [[' 731.09']\n",
            "  [' 62.4']\n",
            "  [' 94.66']\n",
            "  [' 32.415']\n",
            "  [' 40.244']\n",
            "  [' 28.94']]\n",
            "\n",
            " [[' 62.4']\n",
            "  [' 94.66']\n",
            "  [' 32.415']\n",
            "  [' 40.244']\n",
            "  [' 28.94']\n",
            "  [' 55.13']]\n",
            "\n",
            " [[' 94.66']\n",
            "  [' 32.415']\n",
            "  [' 40.244']\n",
            "  [' 28.94']\n",
            "  [' 55.13']\n",
            "  [' 147.62']]\n",
            "\n",
            " [[' 32.415']\n",
            "  [' 40.244']\n",
            "  [' 28.94']\n",
            "  [' 55.13']\n",
            "  [' 147.62']\n",
            "  [' 88.57']]\n",
            "\n",
            " [[' 40.244']\n",
            "  [' 28.94']\n",
            "  [' 55.13']\n",
            "  [' 147.62']\n",
            "  [' 88.57']\n",
            "  [' 83.53']]\n",
            "\n",
            " [[' 28.94']\n",
            "  [' 55.13']\n",
            "  [' 147.62']\n",
            "  [' 88.57']\n",
            "  [' 83.53']\n",
            "  [' 18.975']]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I6bRYECCxii2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_reg_model(layer_units=[100,100],dropouts=[0.2,0.2],window_size=50):\n",
        "    # build LSTM network\n",
        "    model = Sequential()\n",
        "\n",
        "    # hidden layer 1\n",
        "    model.add(LSTM(layer_units[0],\n",
        "                   input_shape=(window_size,1),\n",
        "                   return_sequences=True))\n",
        "    model.add(Dropout(dropouts[0]))\n",
        "\n",
        "    # hidden layer 2\n",
        "    model.add(LSTM(layer_units[1]))\n",
        "    model.add(Dropout(dropouts[1]))\n",
        "\n",
        "    # output layer\n",
        "    model.add(Dense(1))\n",
        "    model.add(Activation(\"linear\"))\n",
        "\n",
        "    start = time.time()\n",
        "    model.compile(loss=\"mse\", optimizer=\"rmsprop\")\n",
        "    print(\"> Compilation Time : \", time.time() - start)\n",
        "    print(model.summary())\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pSjdrXlnXJTF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Set Parameters\n",
        "WINDOW=6\n",
        "PRED_LENGTH = int(WINDOW/2)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ctLk1glxiFm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "0b5ce279-2d84-4255-8d4b-8d787ceb88e8"
      },
      "source": [
        " lstm_model=None\n",
        " try:\n",
        "   lstm_model = get_reg_model(layer_units=[50,100],\n",
        "                               window_size=WINDOW)\n",
        " except:\n",
        "   print(\"Model Build Failed. Trying Again\")\n",
        "   lstm_model = get_reg_model(layer_units=[50,100],\n",
        "                               window_size=WINDOW)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "> Compilation Time :  0.015786170959472656\n",
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_15 (LSTM)               (None, 6, 50)             10400     \n",
            "_________________________________________________________________\n",
            "dropout_15 (Dropout)         (None, 6, 50)             0         \n",
            "_________________________________________________________________\n",
            "lstm_16 (LSTM)               (None, 100)               60400     \n",
            "_________________________________________________________________\n",
            "dropout_16 (Dropout)         (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 1)                 101       \n",
            "_________________________________________________________________\n",
            "activation_8 (Activation)    (None, 1)                 0         \n",
            "=================================================================\n",
            "Total params: 70,901\n",
            "Trainable params: 70,901\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0gnuEFkC7fuy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0bdb47a3-71b1-43ca-fa81-c39dab20706d"
      },
      "source": [
        "   # use eatrly stopping to avoid overfitting\n",
        "    callbacks = [keras.callbacks.EarlyStopping(monitor='val_loss',\n",
        "                                               patience=2,\n",
        "                                               verbose=0)]\n",
        "    lstm_model.fit(x_train, y_train,\n",
        "                   epochs=20, batch_size=16,\n",
        "                   verbose=1,validation_split=0.05,\n",
        "                   callbacks=callbacks)\n",
        "    print(\"Model Fit Complete\")"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 13 samples, validate on 1 samples\n",
            "Epoch 1/20\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "13/13 [==============================] - 11s 849ms/step - loss: 46185.3750 - val_loss: 13482.5938\n",
            "Epoch 2/20\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 46031.0469 - val_loss: 13350.4170\n",
            "Epoch 3/20\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 45895.9453 - val_loss: 13206.3555\n",
            "Epoch 4/20\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 45769.7422 - val_loss: 13040.9004\n",
            "Epoch 5/20\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 45599.1250 - val_loss: 12842.3643\n",
            "Epoch 6/20\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 45427.7656 - val_loss: 12620.7910\n",
            "Epoch 7/20\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 45214.3164 - val_loss: 12383.6221\n",
            "Epoch 8/20\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 44977.4609 - val_loss: 12142.3408\n",
            "Epoch 9/20\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 44802.3711 - val_loss: 11916.2598\n",
            "Epoch 10/20\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 44589.1211 - val_loss: 11694.0684\n",
            "Epoch 11/20\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 44211.3789 - val_loss: 11467.4160\n",
            "Epoch 12/20\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 44146.0703 - val_loss: 11273.2871\n",
            "Epoch 13/20\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 43766.4414 - val_loss: 11107.1084\n",
            "Epoch 14/20\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 43710.4297 - val_loss: 10973.2510\n",
            "Epoch 15/20\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 43617.3047 - val_loss: 10875.4863\n",
            "Epoch 16/20\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 43502.7500 - val_loss: 10792.5830\n",
            "Epoch 17/20\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 43408.1406 - val_loss: 10719.5938\n",
            "Epoch 18/20\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 43228.6914 - val_loss: 10655.1387\n",
            "Epoch 19/20\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 43317.1328 - val_loss: 10604.4004\n",
            "Epoch 20/20\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 43137.8281 - val_loss: 10558.2900\n",
            "Model Fit Complete\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cI4qNY1H96vL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "voelLbAe822y",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n"
      ]
    }
  ]
}