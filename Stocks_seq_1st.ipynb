{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Stocks_seq_1st.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sfwtopoulos/stocks/blob/master/Stocks_seq_1st.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DOmxraS5T1wD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import math\n",
        "import warnings\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "import pandas_datareader as pdr\n",
        "#%tensorflow_version 2.x\n",
        "# Restart runtime using 'Runtime' -> 'Restart runtime...'\n",
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "\n",
        "\n",
        "from keras.layers import LSTM\n",
        "from keras.models import Sequential\n",
        "from keras.layers.wrappers import TimeDistributed\n",
        "from keras.layers.core import Dense, Activation, Dropout\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "#not all needed\n",
        "\n",
        "\n",
        "warnings.filterwarnings('ignore',category=FutureWarning)\n",
        "warnings.filterwarnings('ignore', category=DeprecationWarning)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2byEjZdZVJrz",
        "colab_type": "code",
        "outputId": "5a656736-0237-414f-d897-7ad0fb3aa732",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(keras.__version__)\n",
        "print(tf.__version__)\n",
        "#print(tensorflow.compat.v2.__version__)"
      ],
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.2.5\n",
            "1.15.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tVJdUlQJUDjY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Data import from git repo\n",
        "url = 'https://raw.githubusercontent.com/sfwtopoulos/stocks/master/stocks_dataset/combined.csv'\n",
        "#df1 = pd.read_csv(url, error_bad_lines=False)\n",
        "dfstocks = pd.read_csv(url, sep=',')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A1gYAB3OUECs",
        "colab_type": "code",
        "outputId": "9bd097e3-0a87-41b6-f15e-1b9cef41e11c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "#fix column names\n",
        "dfstocks=dfstocks.rename({' AAPL':'Company', ' Close/Last':'Close', ' Volume':'Volume', ' Open':'Open', ' High':'High', ' Low':'Low'}, axis=1);\n",
        "for col in dfstocks.columns: \n",
        "    print(col) "
      ],
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Date\n",
            "Close\n",
            "Volume\n",
            "Open\n",
            "High\n",
            "Low\n",
            "Company\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vlSTPXYHUHSB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#drop $sign from values\n",
        "dfstocks.Close=dfstocks['Close'].astype(str)\n",
        "dfstocks.Close=dfstocks.Close.apply(lambda x: x.replace('$',''))\n",
        "dfstocks.Open=dfstocks['Open'].astype(str)\n",
        "dfstocks.Open=dfstocks.Open.apply(lambda x: x.replace('$',''))\n",
        "dfstocks.High=dfstocks['High'].astype(str)\n",
        "dfstocks.High=dfstocks.High.apply(lambda x: x.replace('$',''))\n",
        "dfstocks.Low=dfstocks['Low'].astype(str)\n",
        "dfstocks.Low=dfstocks.Low.apply(lambda x: x.replace('$',''))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F4cxCV_YUJGa",
        "colab_type": "code",
        "outputId": "2a01a0a2-8cc4-496e-ca36-b1168ead2991",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#drop rows containing nan or header from the csv files\n",
        "dfstocks=dfstocks[~dfstocks.Low.str.contains(\"nan\")]\n",
        "dfstocks=dfstocks[~dfstocks.Low.str.contains(\"Low\")]\n",
        "dfstocks=dfstocks[~dfstocks.Low.str.contains(\"N/A\")]\n",
        "dfstocks=dfstocks[~dfstocks.Volume.str.contains(\"N/A\")]\n",
        "dfstocks.reset_index(drop=True, inplace=True)\n",
        "dfstocks.Date.count()"
      ],
      "execution_count": 175,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "229269"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 175
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "te4JUA9lUL06",
        "colab_type": "code",
        "outputId": "f706a67c-3de1-422f-83af-2689d529e7eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "#sort dataframe based on date and Company Name\n",
        "dfstocks = dfstocks.sort_values(['Date', 'Company'])\n",
        "dfstocks.head(100)"
      ],
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Company</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>01/02/2013</td>\n",
              "      <td>78.4328</td>\n",
              "      <td>139906732</td>\n",
              "      <td>79.1171</td>\n",
              "      <td>79.2857</td>\n",
              "      <td>77.3757</td>\n",
              "      <td>AAPL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>01/02/2013</td>\n",
              "      <td>35.1200</td>\n",
              "      <td>13767660</td>\n",
              "      <td>34.92</td>\n",
              "      <td>35.4</td>\n",
              "      <td>34.1</td>\n",
              "      <td>ABBV</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>01/02/2013</td>\n",
              "      <td>32.0500</td>\n",
              "      <td>20266410</td>\n",
              "      <td>32.3</td>\n",
              "      <td>32.45</td>\n",
              "      <td>31.64</td>\n",
              "      <td>ABT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>01/02/2013</td>\n",
              "      <td>69.0600</td>\n",
              "      <td>4039095</td>\n",
              "      <td>67.59</td>\n",
              "      <td>69.06</td>\n",
              "      <td>67.55</td>\n",
              "      <td>ACN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>01/02/2013</td>\n",
              "      <td>38.3400</td>\n",
              "      <td>6483720</td>\n",
              "      <td>37.92</td>\n",
              "      <td>38.73</td>\n",
              "      <td>37.92</td>\n",
              "      <td>ADBE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>01/02/2014</td>\n",
              "      <td>59.2900</td>\n",
              "      <td>2745895</td>\n",
              "      <td>59.06</td>\n",
              "      <td>59.53</td>\n",
              "      <td>58.94</td>\n",
              "      <td>ADBE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>01/02/2014</td>\n",
              "      <td>168.0500</td>\n",
              "      <td>1268722</td>\n",
              "      <td>167.33</td>\n",
              "      <td>170.71</td>\n",
              "      <td>166.5937</td>\n",
              "      <td>AGN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>01/02/2014</td>\n",
              "      <td>50.7100</td>\n",
              "      <td>9196092</td>\n",
              "      <td>50.81</td>\n",
              "      <td>51.3</td>\n",
              "      <td>50.47</td>\n",
              "      <td>AIG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>01/02/2014</td>\n",
              "      <td>53.5500</td>\n",
              "      <td>1909106</td>\n",
              "      <td>54.09</td>\n",
              "      <td>54.45</td>\n",
              "      <td>53.5</td>\n",
              "      <td>ALL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>01/02/2014</td>\n",
              "      <td>115.7950</td>\n",
              "      <td>2528751</td>\n",
              "      <td>114.36</td>\n",
              "      <td>116.19</td>\n",
              "      <td>114.06</td>\n",
              "      <td>AMGN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          Date     Close      Volume      Open      High        Low Company\n",
              "0   01/02/2013   78.4328   139906732   79.1171   79.2857    77.3757    AAPL\n",
              "1   01/02/2013   35.1200    13767660     34.92      35.4       34.1    ABBV\n",
              "2   01/02/2013   32.0500    20266410      32.3     32.45      31.64     ABT\n",
              "3   01/02/2013   69.0600     4039095     67.59     69.06      67.55     ACN\n",
              "4   01/02/2013   38.3400     6483720     37.92     38.73      37.92    ADBE\n",
              "..         ...       ...         ...       ...       ...        ...     ...\n",
              "95  01/02/2014   59.2900     2745895     59.06     59.53      58.94    ADBE\n",
              "96  01/02/2014  168.0500     1268722    167.33    170.71   166.5937     AGN\n",
              "97  01/02/2014   50.7100     9196092     50.81      51.3      50.47     AIG\n",
              "98  01/02/2014   53.5500     1909106     54.09     54.45       53.5     ALL\n",
              "99  01/02/2014  115.7950     2528751    114.36    116.19     114.06    AMGN\n",
              "\n",
              "[100 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 176
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ORS6zOAhUMQ6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Test Split\n",
        "dfstocks_split = dfstocks.sample(frac=0.9998,random_state=200)\n",
        "second_split=dfstocks.drop(dfstocks_split.index)\n",
        "# second_split = second_split.reindex(index=second_split.Date(second_split.index.min(), \n",
        "#                                           second_split.index.max(), \n",
        "#                                           freq='D')).fillna(method='ffill')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SvGv9U_NHZcv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "e17f3155-91c8-4961-e35a-45c8d1e3ae64"
      },
      "source": [
        "#Converting Datatypes\n",
        "dfstocks.Date=pd.to_datetime(dfstocks.Date)\n",
        "dfstocks.Close=pd.to_numeric(dfstocks.Close)\n",
        "dfstocks.Volume=pd.to_numeric(dfstocks.Volume)\n",
        "dfstocks.Open=pd.to_numeric(dfstocks.Open)\n",
        "dfstocks.High=pd.to_numeric(dfstocks.High)\n",
        "dfstocks.Low=pd.to_numeric(dfstocks.Low)\n",
        "dfstocks.dtypes"
      ],
      "execution_count": 187,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Date       datetime64[ns]\n",
              "Close             float64\n",
              "Volume              int64\n",
              "Open              float64\n",
              "High              float64\n",
              "Low               float64\n",
              "Company            object\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 187
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rsD9-1pONB6V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5c7d7cfe-c71e-4f2f-f522-8445a889f63e"
      },
      "source": [
        "#dfstocks[dfstocks['Company'].str.contains(\"AMZN\")]\n",
        "second_split=dfstocks[dfstocks['Company'].str.contains(\"AMZN\")]\n",
        "second_split.isnull().values.any()\n",
        "second_split.isna().values.any()\n",
        "second_split.reset_index(drop=True, inplace=True)\n",
        "second_split.shape[0]"
      ],
      "execution_count": 197,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2487"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 197
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "te-gSnYPU0wX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "0d8b3016-6cfa-4083-a061-8bbdcdc1d716"
      },
      "source": [
        "second_split"
      ],
      "execution_count": 198,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Company</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2013-01-02</td>\n",
              "      <td>257.31</td>\n",
              "      <td>3270560</td>\n",
              "      <td>256.08</td>\n",
              "      <td>258.0999</td>\n",
              "      <td>253.2600</td>\n",
              "      <td>AMZN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2014-01-02</td>\n",
              "      <td>397.97</td>\n",
              "      <td>2137807</td>\n",
              "      <td>398.80</td>\n",
              "      <td>399.3600</td>\n",
              "      <td>394.0200</td>\n",
              "      <td>AMZN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2015-01-02</td>\n",
              "      <td>308.52</td>\n",
              "      <td>2785167</td>\n",
              "      <td>312.58</td>\n",
              "      <td>314.7500</td>\n",
              "      <td>306.9601</td>\n",
              "      <td>AMZN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2018-01-02</td>\n",
              "      <td>1189.01</td>\n",
              "      <td>2673958</td>\n",
              "      <td>1172.00</td>\n",
              "      <td>1190.0000</td>\n",
              "      <td>1170.5100</td>\n",
              "      <td>AMZN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2019-01-02</td>\n",
              "      <td>1539.13</td>\n",
              "      <td>7871967</td>\n",
              "      <td>1465.20</td>\n",
              "      <td>1553.3600</td>\n",
              "      <td>1460.9300</td>\n",
              "      <td>AMZN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2482</th>\n",
              "      <td>2013-12-31</td>\n",
              "      <td>398.79</td>\n",
              "      <td>1996089</td>\n",
              "      <td>394.58</td>\n",
              "      <td>398.8300</td>\n",
              "      <td>393.8000</td>\n",
              "      <td>AMZN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2483</th>\n",
              "      <td>2014-12-31</td>\n",
              "      <td>310.35</td>\n",
              "      <td>2048676</td>\n",
              "      <td>311.55</td>\n",
              "      <td>312.9800</td>\n",
              "      <td>310.0100</td>\n",
              "      <td>AMZN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2484</th>\n",
              "      <td>2015-12-31</td>\n",
              "      <td>675.89</td>\n",
              "      <td>3745197</td>\n",
              "      <td>686.08</td>\n",
              "      <td>687.7500</td>\n",
              "      <td>675.8900</td>\n",
              "      <td>AMZN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2485</th>\n",
              "      <td>2018-12-31</td>\n",
              "      <td>1501.97</td>\n",
              "      <td>6941598</td>\n",
              "      <td>1510.80</td>\n",
              "      <td>1520.7600</td>\n",
              "      <td>1487.0000</td>\n",
              "      <td>AMZN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2486</th>\n",
              "      <td>2019-12-31</td>\n",
              "      <td>1847.84</td>\n",
              "      <td>2510380</td>\n",
              "      <td>1842.00</td>\n",
              "      <td>1853.2600</td>\n",
              "      <td>1832.2300</td>\n",
              "      <td>AMZN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2487 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           Date    Close   Volume     Open       High        Low Company\n",
              "0    2013-01-02   257.31  3270560   256.08   258.0999   253.2600    AMZN\n",
              "1    2014-01-02   397.97  2137807   398.80   399.3600   394.0200    AMZN\n",
              "2    2015-01-02   308.52  2785167   312.58   314.7500   306.9601    AMZN\n",
              "3    2018-01-02  1189.01  2673958  1172.00  1190.0000  1170.5100    AMZN\n",
              "4    2019-01-02  1539.13  7871967  1465.20  1553.3600  1460.9300    AMZN\n",
              "...         ...      ...      ...      ...        ...        ...     ...\n",
              "2482 2013-12-31   398.79  1996089   394.58   398.8300   393.8000    AMZN\n",
              "2483 2014-12-31   310.35  2048676   311.55   312.9800   310.0100    AMZN\n",
              "2484 2015-12-31   675.89  3745197   686.08   687.7500   675.8900    AMZN\n",
              "2485 2018-12-31  1501.97  6941598  1510.80  1520.7600  1487.0000    AMZN\n",
              "2486 2019-12-31  1847.84  2510380  1842.00  1853.2600  1832.2300    AMZN\n",
              "\n",
              "[2487 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 198
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0behU6tsViUy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TRAIN_PERCENT = 0.7\n",
        "#STOCK_INDEX = '^GSPC'\n",
        "VERBOSE=True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wjwirxd4VutM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# prepare training and testing data sets for LSTM based sequence modeling\n",
        "#def get_seq_train_test(time_series, scaling=True,train_size=0.9):\n",
        "def get_seq_train_test(time_series,train_size=0.9):\n",
        "    # scaler = None\n",
        "    # if scaling:\n",
        "    #     scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "    time_series = np.array(time_series).reshape(-1,1)\n",
        "    #     scaled_stock_series = scaler.fit_transform(time_series)\n",
        "    # else:\n",
        "    #     scaled_stock_series = time_series\n",
        "    scaled_stock_series = time_series\n",
        "        \n",
        "    #train_size = int(len(scaled_stock_series) * train_size)\n",
        "    train_size = int(len(time_series) * train_size)\n",
        "\n",
        "    #train = scaled_stock_series[0:train_size]\n",
        "    train = time_series[0:train_size]\n",
        "    #test = scaled_stock_series[train_size:len(scaled_stock_series)]\n",
        "    test = time_series[train_size:len(time_series)]\n",
        "    \n",
        "    return train,test \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UN6DYJT7TXPb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_seq_model(hidden_units=4,input_shape=(1,1),verbose=False):\n",
        "    # create and fit the LSTM network\n",
        "    model = Sequential()\n",
        "    # samples*timesteps*featuress\n",
        "\n",
        "    model.add(LSTM(input_shape=input_shape,\n",
        "                   units = hidden_units,\n",
        "                   return_sequences=True\n",
        "    ))\n",
        "\n",
        "    # readout layer. TimeDistributedDense uses the same weights for all\n",
        "    # time steps.\n",
        "    model.add(TimeDistributed(Dense(1)))\n",
        "    start = time.time()\n",
        "\n",
        "    model.compile(loss=\"mse\", optimizer=\"rmsprop\")\n",
        "\n",
        "    if verbose:\n",
        "        print(\"> Compilation Time : \", time.time() - start)\n",
        "        print(model.summary())\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zeAENS4LVpDG",
        "colab_type": "code",
        "outputId": "f7e9da3c-ca0c-4e2b-fab8-173d89e8f2da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "# split train and test datasets\n",
        "train,test = get_seq_train_test(second_split.Close,\n",
        "#                                  scaling=True,\n",
        "                                   train_size=TRAIN_PERCENT)\n",
        "\n",
        "#train\n",
        "print(len(train))\n",
        "print(train.shape[0])\n",
        "print(train.shape)\n",
        "print(test.shape)"
      ],
      "execution_count": 202,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1740\n",
            "1740\n",
            "(1740, 1)\n",
            "(747, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZG7396CWoy9",
        "colab_type": "code",
        "outputId": "bae18457-afbb-401b-ec39-efd8c2ab5f3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "#We use numpy to reshape our time seriesinto 3D tensors.\n",
        "train = np.reshape(train,(1,train.shape[0],1))\n",
        "test = np.reshape(test,(1,test.shape[0],1))\n",
        "\n",
        "train_x = train[:,:-1,:]\n",
        "train_y = train[:,1:,:]\n",
        "\n",
        "test_x = test[:,:-1,:]\n",
        "test_y = test[:,1:,:]\n",
        "\n",
        "print(\"Data Split Complete\")\n",
        "\n",
        "print(\"train_x shape={}\".format(train_x.shape))\n",
        "print(\"train_y shape={}\".format(train_y.shape))\n",
        "print(\"test_x shape={}\".format(test_x.shape))\n",
        "print(\"test_y shape={}\".format(test_y.shape))"
      ],
      "execution_count": 203,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data Split Complete\n",
            "train_x shape=(1, 1739, 1)\n",
            "train_y shape=(1, 1739, 1)\n",
            "test_x shape=(1, 746, 1)\n",
            "test_y shape=(1, 746, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DqTCq2NDTQFL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "da2f2959-28da-40c5-ea03-54db2c7bedd6"
      },
      "source": [
        "# build RNN model\n",
        "seq_lstm_model=None\n",
        "try:\n",
        "    seq_lstm_model = get_seq_model(input_shape=(train_x.shape[1],1),\n",
        "                                                verbose=VERBOSE)\n",
        "except:\n",
        "    print(\"Model Build Failed. Trying Again\")\n",
        "    seq_lstm_model = get_seq_model(input_shape=(train_x.shape[1],1),\n",
        "                                                verbose=VERBOSE)"
      ],
      "execution_count": 204,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "> Compilation Time :  0.01675248146057129\n",
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_4 (LSTM)                (None, 1739, 4)           96        \n",
            "_________________________________________________________________\n",
            "time_distributed_4 (TimeDist (None, 1739, 1)           5         \n",
            "=================================================================\n",
            "Total params: 101\n",
            "Trainable params: 101\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FnQs_OC6XsTz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "50245e6b-8ba6-4d2e-d966-b30acf6ddfaf"
      },
      "source": [
        "# train the model\n",
        "seq_lstm_model.fit(train_x, train_y,\n",
        "                epochs=150, batch_size=1,\n",
        "                verbose=2)\n",
        "print(\"Model Fit Complete\")"
      ],
      "execution_count": 205,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            " - 2s - loss: 783087.8750\n",
            "Epoch 2/150\n",
            " - 1s - loss: 783079.5000\n",
            "Epoch 3/150\n",
            " - 1s - loss: 783073.3750\n",
            "Epoch 4/150\n",
            " - 1s - loss: 783068.3750\n",
            "Epoch 5/150\n",
            " - 1s - loss: 783063.8125\n",
            "Epoch 6/150\n",
            " - 1s - loss: 783059.6250\n",
            "Epoch 7/150\n",
            " - 1s - loss: 783055.6875\n",
            "Epoch 8/150\n",
            " - 1s - loss: 783051.8125\n",
            "Epoch 9/150\n",
            " - 1s - loss: 783048.5625\n",
            "Epoch 10/150\n",
            " - 1s - loss: 783044.8750\n",
            "Epoch 11/150\n",
            " - 1s - loss: 780877.4375\n",
            "Epoch 12/150\n",
            " - 1s - loss: 780226.0000\n",
            "Epoch 13/150\n",
            " - 1s - loss: 780222.6875\n",
            "Epoch 14/150\n",
            " - 1s - loss: 780219.5625\n",
            "Epoch 15/150\n",
            " - 1s - loss: 780216.5000\n",
            "Epoch 16/150\n",
            " - 1s - loss: 780213.3750\n",
            "Epoch 17/150\n",
            " - 1s - loss: 780210.4375\n",
            "Epoch 18/150\n",
            " - 1s - loss: 780207.5625\n",
            "Epoch 19/150\n",
            " - 1s - loss: 780204.7500\n",
            "Epoch 20/150\n",
            " - 1s - loss: 780201.7500\n",
            "Epoch 21/150\n",
            " - 1s - loss: 780198.9375\n",
            "Epoch 22/150\n",
            " - 1s - loss: 780196.0000\n",
            "Epoch 23/150\n",
            " - 1s - loss: 780193.1875\n",
            "Epoch 24/150\n",
            " - 1s - loss: 780190.5625\n",
            "Epoch 25/150\n",
            " - 1s - loss: 780187.6250\n",
            "Epoch 26/150\n",
            " - 1s - loss: 780184.8125\n",
            "Epoch 27/150\n",
            " - 1s - loss: 780182.0625\n",
            "Epoch 28/150\n",
            " - 1s - loss: 780179.3125\n",
            "Epoch 29/150\n",
            " - 1s - loss: 780176.5000\n",
            "Epoch 30/150\n",
            " - 1s - loss: 780173.8125\n",
            "Epoch 31/150\n",
            " - 1s - loss: 780171.1875\n",
            "Epoch 32/150\n",
            " - 1s - loss: 780168.3750\n",
            "Epoch 33/150\n",
            " - 1s - loss: 780165.6875\n",
            "Epoch 34/150\n",
            " - 1s - loss: 780163.0625\n",
            "Epoch 35/150\n",
            " - 1s - loss: 780160.3125\n",
            "Epoch 36/150\n",
            " - 1s - loss: 780157.6250\n",
            "Epoch 37/150\n",
            " - 1s - loss: 780154.8750\n",
            "Epoch 38/150\n",
            " - 1s - loss: 780152.1250\n",
            "Epoch 39/150\n",
            " - 1s - loss: 780149.6250\n",
            "Epoch 40/150\n",
            " - 1s - loss: 780146.8750\n",
            "Epoch 41/150\n",
            " - 1s - loss: 780144.2500\n",
            "Epoch 42/150\n",
            " - 1s - loss: 780141.5000\n",
            "Epoch 43/150\n",
            " - 1s - loss: 780138.8125\n",
            "Epoch 44/150\n",
            " - 1s - loss: 780136.1250\n",
            "Epoch 45/150\n",
            " - 1s - loss: 780133.5000\n",
            "Epoch 46/150\n",
            " - 1s - loss: 780130.6875\n",
            "Epoch 47/150\n",
            " - 1s - loss: 780128.1250\n",
            "Epoch 48/150\n",
            " - 1s - loss: 780125.3750\n",
            "Epoch 49/150\n",
            " - 1s - loss: 780122.7500\n",
            "Epoch 50/150\n",
            " - 1s - loss: 780120.1250\n",
            "Epoch 51/150\n",
            " - 1s - loss: 780117.4375\n",
            "Epoch 52/150\n",
            " - 1s - loss: 780114.8750\n",
            "Epoch 53/150\n",
            " - 1s - loss: 780112.1875\n",
            "Epoch 54/150\n",
            " - 1s - loss: 780109.5625\n",
            "Epoch 55/150\n",
            " - 1s - loss: 780106.8125\n",
            "Epoch 56/150\n",
            " - 1s - loss: 780104.1250\n",
            "Epoch 57/150\n",
            " - 1s - loss: 780101.5000\n",
            "Epoch 58/150\n",
            " - 1s - loss: 780098.8125\n",
            "Epoch 59/150\n",
            " - 1s - loss: 780096.1875\n",
            "Epoch 60/150\n",
            " - 1s - loss: 780093.4375\n",
            "Epoch 61/150\n",
            " - 1s - loss: 780090.8750\n",
            "Epoch 62/150\n",
            " - 1s - loss: 780088.0625\n",
            "Epoch 63/150\n",
            " - 1s - loss: 780085.5000\n",
            "Epoch 64/150\n",
            " - 1s - loss: 780082.8750\n",
            "Epoch 65/150\n",
            " - 1s - loss: 780080.1250\n",
            "Epoch 66/150\n",
            " - 1s - loss: 780077.5000\n",
            "Epoch 67/150\n",
            " - 1s - loss: 780075.0000\n",
            "Epoch 68/150\n",
            " - 1s - loss: 780072.1250\n",
            "Epoch 69/150\n",
            " - 1s - loss: 780069.4375\n",
            "Epoch 70/150\n",
            " - 1s - loss: 780066.8125\n",
            "Epoch 71/150\n",
            " - 1s - loss: 780064.0625\n",
            "Epoch 72/150\n",
            " - 1s - loss: 780061.5625\n",
            "Epoch 73/150\n",
            " - 1s - loss: 780058.8750\n",
            "Epoch 74/150\n",
            " - 1s - loss: 780056.0625\n",
            "Epoch 75/150\n",
            " - 1s - loss: 780053.6250\n",
            "Epoch 76/150\n",
            " - 1s - loss: 780051.0000\n",
            "Epoch 77/150\n",
            " - 1s - loss: 780048.3125\n",
            "Epoch 78/150\n",
            " - 1s - loss: 780045.6250\n",
            "Epoch 79/150\n",
            " - 1s - loss: 780042.8750\n",
            "Epoch 80/150\n",
            " - 1s - loss: 780040.3125\n",
            "Epoch 81/150\n",
            " - 1s - loss: 780037.6875\n",
            "Epoch 82/150\n",
            " - 1s - loss: 780035.0000\n",
            "Epoch 83/150\n",
            " - 1s - loss: 780032.2500\n",
            "Epoch 84/150\n",
            " - 1s - loss: 780029.5625\n",
            "Epoch 85/150\n",
            " - 1s - loss: 780026.8750\n",
            "Epoch 86/150\n",
            " - 1s - loss: 780024.2500\n",
            "Epoch 87/150\n",
            " - 1s - loss: 780021.6875\n",
            "Epoch 88/150\n",
            " - 1s - loss: 780019.0000\n",
            "Epoch 89/150\n",
            " - 1s - loss: 780016.1875\n",
            "Epoch 90/150\n",
            " - 1s - loss: 780013.7500\n",
            "Epoch 91/150\n",
            " - 1s - loss: 780011.0000\n",
            "Epoch 92/150\n",
            " - 1s - loss: 780008.4375\n",
            "Epoch 93/150\n",
            " - 1s - loss: 780005.8125\n",
            "Epoch 94/150\n",
            " - 1s - loss: 780003.1250\n",
            "Epoch 95/150\n",
            " - 1s - loss: 780000.3750\n",
            "Epoch 96/150\n",
            " - 1s - loss: 779997.6875\n",
            "Epoch 97/150\n",
            " - 1s - loss: 779995.0000\n",
            "Epoch 98/150\n",
            " - 1s - loss: 779992.3750\n",
            "Epoch 99/150\n",
            " - 1s - loss: 779989.7500\n",
            "Epoch 100/150\n",
            " - 1s - loss: 779986.9375\n",
            "Epoch 101/150\n",
            " - 1s - loss: 779984.3750\n",
            "Epoch 102/150\n",
            " - 1s - loss: 779981.5625\n",
            "Epoch 103/150\n",
            " - 1s - loss: 779979.0625\n",
            "Epoch 104/150\n",
            " - 1s - loss: 779976.2500\n",
            "Epoch 105/150\n",
            " - 1s - loss: 779973.7500\n",
            "Epoch 106/150\n",
            " - 1s - loss: 779971.1250\n",
            "Epoch 107/150\n",
            " - 1s - loss: 779968.3750\n",
            "Epoch 108/150\n",
            " - 1s - loss: 779965.8125\n",
            "Epoch 109/150\n",
            " - 1s - loss: 779963.1250\n",
            "Epoch 110/150\n",
            " - 1s - loss: 779960.3750\n",
            "Epoch 111/150\n",
            " - 1s - loss: 779957.8125\n",
            "Epoch 112/150\n",
            " - 1s - loss: 779955.1250\n",
            "Epoch 113/150\n",
            " - 1s - loss: 779952.5000\n",
            "Epoch 114/150\n",
            " - 1s - loss: 779949.8125\n",
            "Epoch 115/150\n",
            " - 1s - loss: 779947.1250\n",
            "Epoch 116/150\n",
            " - 1s - loss: 779944.6250\n",
            "Epoch 117/150\n",
            " - 1s - loss: 779941.8125\n",
            "Epoch 118/150\n",
            " - 1s - loss: 779939.1875\n",
            "Epoch 119/150\n",
            " - 1s - loss: 779936.5625\n",
            "Epoch 120/150\n",
            " - 1s - loss: 779933.8750\n",
            "Epoch 121/150\n",
            " - 1s - loss: 779931.2500\n",
            "Epoch 122/150\n",
            " - 1s - loss: 779928.5625\n",
            "Epoch 123/150\n",
            " - 1s - loss: 779925.8125\n",
            "Epoch 124/150\n",
            " - 1s - loss: 779923.1250\n",
            "Epoch 125/150\n",
            " - 1s - loss: 779920.6250\n",
            "Epoch 126/150\n",
            " - 1s - loss: 779917.9375\n",
            "Epoch 127/150\n",
            " - 1s - loss: 779915.1875\n",
            "Epoch 128/150\n",
            " - 1s - loss: 779912.5625\n",
            "Epoch 129/150\n",
            " - 1s - loss: 779909.9375\n",
            "Epoch 130/150\n",
            " - 1s - loss: 779907.3125\n",
            "Epoch 131/150\n",
            " - 1s - loss: 779904.5625\n",
            "Epoch 132/150\n",
            " - 1s - loss: 779901.9375\n",
            "Epoch 133/150\n",
            " - 1s - loss: 779899.1250\n",
            "Epoch 134/150\n",
            " - 1s - loss: 779896.6250\n",
            "Epoch 135/150\n",
            " - 1s - loss: 779894.0000\n",
            "Epoch 136/150\n",
            " - 1s - loss: 779891.3125\n",
            "Epoch 137/150\n",
            " - 1s - loss: 779888.6875\n",
            "Epoch 138/150\n",
            " - 1s - loss: 779885.8750\n",
            "Epoch 139/150\n",
            " - 1s - loss: 779883.3750\n",
            "Epoch 140/150\n",
            " - 1s - loss: 779880.6875\n",
            "Epoch 141/150\n",
            " - 1s - loss: 779877.9375\n",
            "Epoch 142/150\n",
            " - 1s - loss: 779875.3750\n",
            "Epoch 143/150\n",
            " - 1s - loss: 779872.6250\n",
            "Epoch 144/150\n",
            " - 1s - loss: 779869.9375\n",
            "Epoch 145/150\n",
            " - 1s - loss: 779867.4375\n",
            "Epoch 146/150\n",
            " - 1s - loss: 779864.6875\n",
            "Epoch 147/150\n",
            " - 1s - loss: 779862.1250\n",
            "Epoch 148/150\n",
            " - 1s - loss: 779859.4375\n",
            "Epoch 149/150\n",
            " - 1s - loss: 779856.6250\n",
            "Epoch 150/150\n",
            " - 1s - loss: 779854.1250\n",
            "Model Fit Complete\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g07f1lEGXu_T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "446b32c7-79bf-48e1-97b3-7bf6c294da68"
      },
      "source": [
        "# train fit performance\n",
        "trainPredict = seq_lstm_model.predict(train_x)\n",
        "trainScore = math.sqrt(mean_squared_error(train_y[0], trainPredict[0]))\n",
        "print('Train Score: %.2f RMSE' % (trainScore))"
      ],
      "execution_count": 206,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Score: 883.09 RMSE\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZW0LgTTSXyKR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Pad input sequence\n",
        "testPredict = pad_sequences(test_x,maxlen=train_x.shape[1],padding='post',dtype='float64')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XsR5ytjpX2yj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "dd4cc660-1f39-4d7c-890e-27b99591453b"
      },
      "source": [
        "# forecast values\n",
        "testPredict = seq_lstm_model.predict(testPredict)"
      ],
      "execution_count": 219,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-219-a2727997d9c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtestPredict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseq_lstm_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestPredict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1379\u001b[0m         \u001b[0;31m# Case 2: Symbolic tensors or Numpy array-like.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1380\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_standardize_user_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1381\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1382\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    755\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 757\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    758\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    129\u001b[0m                         \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' dimensions, but got array '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    132\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected lstm_4_input to have 3 dimensions, but got array with shape (1739, 1)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_XhF1MjX4gh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# forecast values\n",
        "testPredict = seq_lstm_model.predict(testPredict)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zA7Aehl4X5ck",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # inverse transformation\n",
        "# scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "# trainPredict = scaler.inverse_transform(trainPredict.\\\n",
        "#                                         reshape(trainPredict.shape[1]))\n",
        "# testPredict = scaler.inverse_transform(testPredict.\\\n",
        "#                                         reshape(testPredict.shape[1]))\n",
        "\n",
        "trainPredict=trainPredict.reshape(trainPredict.shape[1])\n",
        "testPredict=testPredict.reshape(testPredict.shape[1])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_nZ9samd1Rs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "df3711b3-e0e5-4083-cfb3-0c6d8ee6a159"
      },
      "source": [
        "trainPredict"
      ],
      "execution_count": 216,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.96903205, 1.2868543 , 1.3433883 , ..., 1.3567629 , 1.3567629 ,\n",
              "       1.3567629 ], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 216
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7HRKCZ0WX9kC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "93953997-30c1-417f-c11f-89e03f17e84c"
      },
      "source": [
        "# plot the true and forecasted values\n",
        "train_size = len(trainPredict)+1\n",
        "\n",
        "plt.plot(second_split.Close.index,\n",
        "          second_split.Close.values,c='black',\n",
        "          alpha=0.3,label='True Data')\n",
        "plt.plot(second_split.Close.index[1:train_size],\n",
        "          trainPredict,label='Training Fit',c='g')\n",
        "plt.plot(second_split.Close.index[train_size+1:],\n",
        "          testPredict[:test_x.shape[1]],label='Testing Forecast')\n",
        "plt.title('Forecast Plot')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 213,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEICAYAAACzliQjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\njvx/ZCnS8QSiTbAAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}